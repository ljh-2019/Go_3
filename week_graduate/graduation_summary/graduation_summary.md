# 毕业总结



## Q1: 为什么会有微服务？
>1. 之前一般是一个单一的巨石架构，存在很多问题
 1.1 应用比较复杂，没有人能够搞懂
 1.2 应用扩展比较复杂，可靠性比较低
 1.3 无法进行敏捷开发和部署
>2. 所以一般这个时候就会考虑按照服务、功能进行拆分


## Q2: 微服务是什么？

1.SOA （面向服务）是什么？
 <br>1.1 服务拆分后比较小，BUG 少，容易测试和维护，也容易扩展
 <br>1.2 单一职责，一个服务只做一件事情
 <br>1.3 尽可能的早的创建原型，先定义 API，达成契约
 <br>1.4 可移植性比效率更重要，通讯协议的可移植性更加重要

2.SOA 和 微服务 是什么关系？
<br>2.1 微服务是 SOA 的一种实践，微服务也是面向服务的一种架构
<br>3.微服务是什么？
<br>3.1围绕业务功能构建的，服务关注单一业务，服务间采用轻量级的通信机制，可以全自动独立部署，可以使用不同的编程语言和数据存储技术。

## Q3: 微服务可以带来那些好处，又有哪些缺点？
优点
<br>服务拆分后比较小，BUG 少，容易测试和维护，也容易扩展
<br>原子服务，一个服务只做一件事情，并且这个属于这个服务的也不应该拆分到其他服务去
<br>独立进程，一个服务只有一个独立进程，可以很好的和当前的容器化进行结合，无状态的服务可以很容易的享受到，k8s 上的故障转移，自动重启等好处
<br>隔离部署，每个服务之间独立部署，可以避免相互影响，并且和按需进行分配资源，节省成本

缺点
<br>服务之间的依赖关系复杂，成千上万个服务相互依赖就像一团乱麻一样，剪不断理还乱。
<br>微服务本身是分布式系统，需要使用 RPC 或者 消息进行通信，此外，必须要写代码来处理消息传递中速度过慢或者服务不可用等局部失效问题
<br>会有分布式事务问题，因为现在每个微服务之间都会有一个独立的数据库，事务在单体应用中很好处理，但是在跨服务时会变得很麻烦


## 服务间通信方式: gRPC
1. 为什么采用 gRPC?
   <br>多语言：语言中立，支持多种语言。
   <br>轻量级、高性能：序列化支持 PB(Protocol Buffer)和 JSON，PB 是一种语言无关的高性能序列化框架。
   <br>可插拔
   <br>IDL：基于文件定义服务，通过 proto3 工具生成指定语言的数据结构、服务端接口以及客户端 Stub。
   <br>移动端：基于标准的 HTTP2 设计，支持双向流、消息头压缩、单 TCP 的多路复用、服务端推送等特性，这些特性使得 gRPC 在移动端设备上更加省电和节省网络流量。
   <br>服务而非对象、消息而非引用：促进微服务的系统间粗粒度消息交互设计理念。
   <br>负载无关的：不同的服务需要使用不同的消息类型和编码，例如 protocol buffers、JSON、XML 和 Thrift。
流：Streaming API。
   <br>阻塞式和非阻塞式：支持异步和同步处理在客户端和服务端间交互的消息序列。
   <br>元数据交换：常见的横切关注点，如认证或跟踪，依赖数据交换。
metadata
   <br>标准化状态码：客户端通常以有限的方式响应 API 调用返回的错误。<br>
   
2. 为什么不使用 restful
   <br>每个客户端都需要单独写 SDK，复杂麻烦
   <br>需要单独写文档，常常会因为代码更新了但是文档没更新陷入坑中
   <br>性能不太好，json 传递相对于 pb 更耗流量，性能更低
   <br>http1.1 是一个单连接的请求，在内部网络环境，使用 http 比较浪费
   <br>restful 是一个松散约束的协议，非常灵活，每个人，每个团队出来的代码都不太一样，比较容易出错

## panic
<br>在程序启动的时候，如果有强依赖的服务出现故障时 panic 退出
<br>在程序启动的时候，如果发现有配置明显不符合要求， 可以 panic 退出（防御编程）
<br>其他情况下只要不是不可恢复的程序错误，都不应该直接 panic 应该返回 error
<br>在程序入口处，例如 gin 中间件需要使用 recover 预防 panic 程序退出

## error
<br>我们在应用程序中使用 github.com/pkg/errors 处理应用错误，注意在公共库当中，我们一般不使用这个
<br>error 应该是函数的最后一个返回值，当 error 不为 nil 时，函数的其他返回值是不可用的状态，不应该对其他返回值做任何期待

## Goroutine
<br>1.请将是否异步调用的选择权交给调用者，不然很有可能大家并不知道你在这个函数里面使用了 goroutine
<br>2.如果你要启动一个 goroutine 请对它负责
2.1永远不要启动一个你无法控制它退出，或者你无法知道它何时推出的 goroutine
2.2还有上一篇提到的，启动 goroutine 时请加上 panic recovery 机制，避免服务直接不可用
2.3造成 goroutine 泄漏的主要原因就是 goroutine 中造成了阻塞，并且没有外部手段控制它退出
<br>3.尽量避免在请求中直接启动 goroutine 来处理问题，而应该通过启动 worker 来进行消费，这样可以避免由于请求量过大，而导致大量创建 goroutine 从而导致 oom，当然如果请求量本身非常小，那当我没说

## Go 内存模型
<br>1.编译器重排，现代编译器为了能够获取到极致的性能，可能会在编译时做一些指令重排，这就会导致有一些在单线程跑的程序在并发执行时出现一些不可预期的意外情况。
<br>2.内存重排，现代 CPU 大多都是多核 CPU，CPU 为了提高性能会在每个核心下设有缓存，现在一般是有三级缓存，其中一二级是 CPU 独有的，这就可能会存在在并发执行时，多个 Goroutine 在不同的 CPU 上执行看到的变量数据不一致的情况发生。
<br>3.hanppens before，如果 e1 发生在 e2 之前，那么我们就说 e2 发生在 e1 之后，如果 e1 既不在 e2 前，也不在 e2 之后，那我们就说这俩是并发的
<br>4.go 语句会在当前 goroutine 开始执行前启动新的 goroutine
<br>5.goroutine 无法确保在程序中的任何事件发生之前退出

## mutex 互斥锁
<br>互斥锁的实现原理，三种模式
<br>Barging: 这种模式是为了提高吞吐量，当锁被释放时，它会唤醒第一个等待者，然后把锁给第一个等待者或者给第一个请求锁的人
<br>Handoff: 当锁释放时候，锁会一直持有直到第一个等待者准备好获取锁。它降低了吞吐量，因为锁被持有，即使另一个 goroutine 准备获取它。
<br>Spining：自旋在等待队列为空或者应用程序重度使用锁时效果不错。Parking 和 Unparking goroutines 有不低的性能成本开销，相比自旋来说要慢得多。

## context
<br>对 server 应用而言，传入的请求应该创建一个 context，接受
<br>通过 WithCancel , WithDeadline , WithTimeout 创建的 Context 会同时返回一个 cancel 方法，这个方法必须要被执行，不然会导致 context 泄漏，这个可以通过执行 go vet 命令进行检查
<br>应该将 context.Context 作为函数的第一个参数进行传递，参数命名一般为 ctx 不应该将 Context 作为字段放在结构体中。
<br>不要给 context 传递 nil，如果你不知道应该传什么的时候就传递 context.TODO()
<br>不要将函数的可选参数放在 context 当中，context 中一般只放一些全局通用的 metadata 数据，例如 tracing id 等等
<br>context 是并发安全的可以在多个 goroutine 中并发调用
